(24,) 4 1.0
{'ep': 0, 'timesteps': 104, 'ep_reward': -108.34573857267077}
{'ep': 100, 'timesteps': 261, 'ep_reward': -118.1895766721652}
{'ep': 200, 'timesteps': 1600, 'ep_reward': -45.44377434778907}
{'ep': 300, 'timesteps': 1600, 'ep_reward': -99.69221243968819}
{'ep': 400, 'timesteps': 448, 'ep_reward': -116.52113775437326}
{'ep': 500, 'timesteps': 1600, 'ep_reward': 133.64448773515863}
{'ep': 600, 'timesteps': 875, 'ep_reward': -78.05869622189921}
{'ep': 700, 'timesteps': 1600, 'ep_reward': 204.9798492604931}
{'ep': 800, 'timesteps': 153, 'ep_reward': -79.4015915848855}
{'ep': 900, 'timesteps': 1285, 'ep_reward': -172.69149593810053}
{'ep': 1000, 'timesteps': 654, 'ep_reward': -19.944275791044035}
{'ep': 1100, 'timesteps': 1215, 'ep_reward': 283.66174342091085}
{'ep': 1200, 'timesteps': 137, 'ep_reward': -96.29134449220697}
{'ep': 1300, 'timesteps': 1056, 'ep_reward': 283.3887009542174}
{'ep': 1400, 'timesteps': 1103, 'ep_reward': 291.8532690080103}
{'ep': 1500, 'timesteps': 1196, 'ep_reward': 283.9665826918764}
Traceback (most recent call last):
  File "train.py", line 180, in <module>
    main()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train.py", line 153, in main
    train_info = train(agent, env)
  File "train.py", line 50, in train
    agent.record(obs, action, next_obs, reward, done_bool)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/proj/agents/ddpg.py", line 361, in record
    self.buffer.add(state, action, next_state, reward, done)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/common/buffer.py", line 32, in add
    self.reward[self.ptr] = self._to_tensor(reward)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/common/buffer.py", line 26, in _to_tensor
    return torch.tensor(data, dtype=dtype)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 180, in <module>
    main()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train.py", line 153, in main
    train_info = train(agent, env)
  File "train.py", line 50, in train
    agent.record(obs, action, next_obs, reward, done_bool)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/proj/agents/ddpg.py", line 361, in record
    self.buffer.add(state, action, next_state, reward, done)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/common/buffer.py", line 32, in add
    self.reward[self.ptr] = self._to_tensor(reward)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/common/buffer.py", line 26, in _to_tensor
    return torch.tensor(data, dtype=dtype)
KeyboardInterrupt