(24,) 4 1.0
{'ep': 0, 'logstd': array([[0., 0., 0., 0.]], dtype=float32), 'timesteps': 75, 'ep_reward': -103.67519072304107}
Traceback (most recent call last):
  File "train.py", line 183, in <module>
    main()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train.py", line 156, in main
    train_info = train(agent, env)
  File "train.py", line 38, in train
    action, act_logprob = agent.get_action(obs)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/proj/agents/pg.py", line 132, in get_action
    dist = self.policy.forward(x)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/proj/agents/pg.py", line 53, in forward
    probs = Normal(action_mean, action_std)
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/torch/distributions/normal.py", line 45, in __init__
    self.loc, self.scale = broadcast_all(loc, scale)
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/torch/distributions/utils.py", line 27, in broadcast_all
    if not all(isinstance(v, torch.Tensor) or has_torch_function((v,)) or isinstance(v, Number)
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/torch/distributions/utils.py", line 27, in <genexpr>
    if not all(isinstance(v, torch.Tensor) or has_torch_function((v,)) or isinstance(v, Number)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 183, in <module>
    main()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "train.py", line 156, in main
    train_info = train(agent, env)
  File "train.py", line 38, in train
    action, act_logprob = agent.get_action(obs)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/proj/agents/pg.py", line 132, in get_action
    dist = self.policy.forward(x)
  File "/m/home/home7/77/montecc1/data/Desktop/rl_course/proj/agents/pg.py", line 53, in forward
    probs = Normal(action_mean, action_std)
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/torch/distributions/normal.py", line 45, in __init__
    self.loc, self.scale = broadcast_all(loc, scale)
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/torch/distributions/utils.py", line 27, in broadcast_all
    if not all(isinstance(v, torch.Tensor) or has_torch_function((v,)) or isinstance(v, Number)
  File "/u/77/montecc1/unix/.local/lib/python3.8/site-packages/torch/distributions/utils.py", line 27, in <genexpr>
    if not all(isinstance(v, torch.Tensor) or has_torch_function((v,)) or isinstance(v, Number)
KeyboardInterrupt